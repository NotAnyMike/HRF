,folder,tag,env,n,save_interval,train_steps,not_save,env_config,env_num,description,weights,n_steps,weights_location
0,experiments,,<class 'hrl.turn_left.env.CarRacing_turn'>,0,10000,500000,0,,1,,,,
1,experiments,,<class 'hrl.turn_left.env.CarRacing_turn'>,0,10000,500000,0,,1,,,,
2,experiments,,Base,0,10000,500000,0,,1,,,,
3,experiments,Baseline,Base,0,10000,500000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 1, 'num_lanes_changes': 4, 'max_time_out': 2, 'frames_per_state': 4, 'max_episode_reward': 10, 'reward_fn': <function default_reward_callback at 0x7f1e86dc4c80>}",1,,,,
4,experiments,,Base,0,10000,500000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 1, 'num_lanes_changes': 4, 'max_time_out': 2, 'frames_per_state': 4, 'max_episode_reward': 1, 'reward_fn': <function default_reward_callback at 0x7f37eada0bf8>}",1,,,,
5,experiments,,Base,0,10000,500000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 1, 'num_lanes_changes': 4, 'max_time_out': 2, 'frames_per_state': 4, 'max_episode_reward': 1, 'reward_fn': <function default_reward_callback at 0x7f0c0c60cc80>}",1,,,,
6,experiments,left,Turn_left,0,10000,1000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 1, 'num_lanes_changes': 4, 'max_time_out': 2, 'frames_per_state': 4, 'max_episode_reward': 10, 'reward_fn': <function Turn_left.__init__.<locals>.reward_fn at 0x7f132a8e81e0>}",1,,,,
7,experiments,left,Turn_left,0,10000,1000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 1, 'num_lanes_changes': 4, 'max_time_out': 2, 'frames_per_state': 4, 'max_episode_reward': 10, 'reward_fn': <function Turn_left.__init__.<locals>.reward_fn at 0x7f1d0e28e1e0>}",4,,,,
8,experiments,left,Turn_left,0,10000,1000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 1, 'num_lanes_changes': 4, 'max_time_out': 2, 'frames_per_state': 4, 'max_episode_reward': 10, 'reward_fn': <function Turn_left.__init__.<locals>.reward_fn at 0x7f6b2cdea1e0>}",4,Running with the correct render,,,
9,experiments,left_continuing,Turn_left,0,10000,1000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 1, 'num_lanes_changes': 4, 'max_time_out': 2, 'frames_per_state': 4, 'max_episode_reward': 10, 'reward_fn': <function Turn_left.__init__.<locals>.reward_fn at 0x7fc0557192f0>}",4,Continuing experimetn 8,experiments/8_left/weights_509184.pkl,,
10,experiments,Baseline_v1,Base,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function default_reward_callback at 0x7f8262c93ea0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,New Baseline with more training and using obstacles this time,,,
11,experiments,Turn_left_v1,Turn_left,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_left.__init__.<locals>.reward_fn at 0x7f3fbbc58598>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,Turn left policy with obstacles and new termination policy by the env,,,
12,experiments,Turn_rigth_v1,Turn_right,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn.__init__.<locals>.reward_fn at 0x7fb0146b46a8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,Turn right with same env as the new left policy,,,
13,experiments,Base_v1.1,Base,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function default_reward_callback at 0x7f48a5e2dea0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,"Obstacles, NWHC",,,
14,experiments,Turn_rigth_v1.1,Turn_right,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn.__init__.<locals>.reward_fn at 0x7f0550397a60>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,with the right order in the channels,,,
15,experiments,Turn_left_v1.1,Turn_left,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn.__init__.<locals>.reward_fn at 0x7f9aaafa4d08>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,with the right order in the channels,,,
16,experiments,Turn_left_v1.11_multi,Turn_left,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f17c6027d08>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,"using multi processing, the rest is the same as 15",,200.0,
17,experiments,Turn,Turn,0,4000,100000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7fbbb47282f0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,test of high level policy,,4.0,
18,experiments,Turn,Turn,0,4000,100000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f663b295d90>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,test of high level policy with multiprocessing,,4.0,
19,experiments,Turn,Turn,0,4000,100000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f3ce0044d90>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,multiprocessing not working,,4.0,
20,experiments,Turn,Turn,0,4000,100000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f7b5b8fdd90>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,multiprocessing not working,,50.0,
21,experiments,Turn,Turn,0,4000,100000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f9658024d90>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,"multiprocessing not working, test2",,20.0,
22,experiments,Turn,Turn,0,4000,100000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7fa0d3a76730>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,"multiprocessing not working, test2",,20.0,
23,experiments,Take_center,Take_center,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7fc60800ed08>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,Take center,,200.0,
24,experiments,Take_center,Take_center,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f0b9f5d9c80>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,Take center,,200.0,
25,experiments,Take_center_cont,Take_center,758880,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7fdbfd44fd08>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,Take center continuing from 758880 from 24,experiments/24_Take_center/weights_758880.pkl,200.0,
26,experiments,Take_center_cont2,Take_center,1366800,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f0c70615c80>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,Take center continuing from 1366800 from 25,experiments/25_Take_center_cont/weights_1366800.pkl,200.0,
27,experiments,Take_center_cont3,Take_center,2177088,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7fd21800ed08>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False}",4,Take center continuing from 2177088 from 26,experiments/26_Take_center_cont2/weights_2177088.pkl,200.0,
28,experiments,Turn_n2n,Turn_n2n,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f678c275ea0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'allow_outside': False}",4,Fast experiment with n2n and Turn,,200.0,
29,experiments,Turn_n2n_cont,Turn_n2n,3000000,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7fdfe59ffea0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'allow_outside': False}",4,continuing with n2n,experiments/28_Turn_n2n/weights_final.pkl,200.0,
30,experiments,X,X,0,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f89734181e0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,20.0,
31,experiments,X,X,0,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7efd584581e0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,increasing n_steps,,50.0,
32,experiments,X,X,0,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7ffa468f01e0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,decreasing n_steps,,10.0,
33,experiments,X,X,0,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f7fd351b1e0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,increasing n_steps,,100.0,
34,experiments,X,X,0,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f44e22cb378>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,fixing max_step_reward and 20 n steps,,20.0,
35,experiments,X,X,0,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f22badc6378>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,fixing outside and negative reward for living,,20.0,
36,experiments,X_cont,X,13728,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7faca2cc1400>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,continuing 35 from 13728,experiments/35_X/weights_13728.pkl,20.0,
37,experiments,X_cont,X,42336,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f0bc1b87400>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,continuing 36 from 42336,experiments/36_X_cont/weights_42336.pkl,20.0,
38,experiments,X_cont,X,64608,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f86088ae400>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,continuing 37 from 64608,experiments/37_X_cont/weights_64608.pkl,20.0,
39,experiments,memory_test,Turn,0,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7fdc47eb47b8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,,,20.0,
40,experiments,memory_test2,X,0,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f21b1106840>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,,,20.0,
41,experiments,memory_test2,X,0,1000,75000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f90fa725950>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,20.0,
42,experiments,memory_test2,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7fcb9e219a60>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,20.0,
43,experiments,memory_test2,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7ff0e007da60>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,20.0,
44,experiments,memory_test2,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f29b6faa400>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,20.0,
45,experiments,memory_test2,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f7879bed400>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,20.0,
46,experiments,memory_test2,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f02e973b400>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,20.0,
47,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f8ac6c7e400>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,20.0,
48,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f4ce7934158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking leaking objects before and after reset,,20.0,
49,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7fcc76c9f158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking general objects count,,20.0,
50,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f57f6840158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking general objects count in worker,,20.0,
51,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f862f612158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking general objects count in worker with gc,,20.0,
52,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f25200c00d0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,trying explicitly deleting the obs,,20.0,
53,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f90b0120158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,showing growth,,20.0,
54,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f6a43446158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking leaky objects in worker,,20.0,
55,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7ff2300e3158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking leaky objects in worker,,20.0,
56,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f8ae2fd40d0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,count list != most common types with leaky,,20.0,
57,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f1c858ae0d0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,count list != most common types with leaky with del in roots,,20.0,
58,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7fc56bfb4048>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking in reset if same behaviour as here without deleting roots,,20.0,
59,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f2e59cc7488>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking in reset if same behaviour as here without deleting roots,,20.0,
60,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f99967af488>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking in reset if same behaviour as here without deleting roots,,20.0,
61,experiments,memory_test,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f58a2db3488>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,checking in reset if same behaviour as here without deleting roots,,20.0,
62,experiments,memory_test,X,0,1000,600,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7f3cc0010d90>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,,,20.0,
63,experiments,to_delete,Base,0,10000,1000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function default_reward_callback at 0x7f2fd82d5b70>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks'}",1,,,200.0,
64,experiments,memory_test_solution,X,0,1000,20000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7ff8bcb0f048>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",1,applying solution stated in #34 and testing in training,,20.0,
65,experiments,n2n_b,Turn_n2n,0,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f6b701ad158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,n2n from zero,,200.0,
66,experiments,n2n_b_cont,Turn_n2n,5818080,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f7e951e21e0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,"n2n from zero, cont b",experiments/65_n2n_b/weights_5818080.pkl,200.0,
67,outside_experiments,n2n_b_cont2,Turn_n2n,6830736,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f466b242510>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,"n2n from zero, cont b again",outside_experiments/66_n2n_b_cont/weights_6830736.pkl,200.0,
68,outside_experiments,n2n_c,Turn_n2n,0,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7fd371aee510>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,"n2n from zero, c",,200.0,
69,outside_experiments,n2n_d,Turn_n2n,0,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7efe51f91510>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,"n2n from zero, d",,200.0,
70,outside_experiments,n2n_e,Turn_n2n,0,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f46ade007b8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,"n2n from zero, e",,200.0,
71,outside_experiments,Keep_lane,Keep_lane,0,50000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function default_reward_callback at 0x7f7dcee547b8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,200.0,
72,outside_experiments,Keep_lane_cont,Keep_lane,3000000,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function default_reward_callback at 0x7fc066a268c8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,outside_experiments/71_Keep_lane/weights_final.pkl,200.0,
73,outside_experiments,Turn_left_v1.1,Turn_left,3000000,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7fad3da727b8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,hrl/weights/Turn_left/v1.0.pkl,200.0,
74,outside_experiments,n2n_e_cont,Turn_n2n,961248,50000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f752131f7b8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,outside_experiments/70_n2n_e/weights_961248.pkl,200.0,
75,outside_experiments,Turn_c,Turn,0,4000,300000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f5fb3c9dd90>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,first run on the server,,30.0,
76,outside_experiments,Turn_cont,Turn,48384,8000,300000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f9d649bdf28>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,"Continuing from the version 1.2 of Turn, which I suspect it is the 48384 of 22",hrl/weights/Turn/v1.2.pkl,30.0,
77,outside_experiments,Turn_d,Turn,0,8000,300000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7f4dba7b6d90>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,d repetition for Turn,,30.0,
78,outside_experiments,NWOO_50_steps,NWOO,0,3000,60000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7f1bbf788378>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,"Finding the best parameters for NWOO, seeing if 50 steps per batch is enough",,50.0,
79,outside_experiments,NWOO_10_steps,NWOO,0,3000,60000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7feab1e051e0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,"Finding the best parameters for NWOO, seeing if 10 steps per batch is enough",,10.0,
80,outside_experiments,X_fixed,X,0,5000,225000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 1.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Take_center.__init__.<locals>.reward_fn at 0x7fa01ec12840>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,fixing the max_steps of policies and Turn is not balanced,,20.0,
81,outside_experiments,Turn_from_zero_balanced,Turn,0,8000,300000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 10, 'reward_fn': <function Turn_side.__init__.<locals>.reward_fn at 0x7fce1f4c7400>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Training Trun from zero this time x and t will appear the same number of times,,30.0,
82,outside_experiments,CLeft,Change_to_left,0,100000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function default_reward_callback at 0x7f4a32c3d7b8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,First train of change to left,,200.0,
83,outside_experiments,CRight,Change_to_right,0,100000,3000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function default_reward_callback at 0x7f784ae917b8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,First train of change to right,,200.0,
84,outside_experiments,Turn_left_v2,Turn_left_v2,0,45000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7fe849f21158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,,,200.0,
85,outside_experiments,Turn_right_v2,Turn_right_v2,0,45000,9000000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7f48621f4158>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Using the new Turn_side_v2 based on NWOO env,,200.0,
86,outside_experiments,Change_lane,Change_lane,0,300,60000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function default_reward_callback at 0x7f81640e98c8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Running change lane high level env with n_steps 10,,10.0,
87,outside_experiments,NWO_v1,NWO,0,600,60000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7fa23df19ea0>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Using the policies of Change lane that kind of fail on high speeds - later on this will have to be re do with better policies,,10.0,
88,outside_experiments,NWO_v1.1,NWO,0,1800,180000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7f649dc17b70>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Obstacle value is -100 and not -10 and training 3 times longer than v1,,10.0,
89,outside_experiments,NWO_v1.2,NWO,0,30000,600000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7fc77133cb70>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Obstacle value is -100 and not -10 and training 10 times longer than v1 plus the steps are 5 times bigger,,50.0,
90,outside_experiments,NWO_v1.3,NWO,0,30000,600000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7fcb19403b70>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Obstacle value is -100 and not -10 and training 10 times longer than v1 plus the steps are 30 times bigger,,300.0,
91,outside_experiments,NWO_v1.4,NWO,0,30000,600000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7f7da3965b70>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Obstacle value is -100 and not -10 and training 10 times longer than v1 plus the steps are 1000 times bigger,,1000.0,
92,outside_experiments,Turn_v2,Turn_v2,0,12000,300000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7f2d57b1b9d8>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Using the new Turn env based on NWOO,,30.0,
93,outside_experiments,NWO_v1.5,NWO,0,30000,600000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7f9c543a2048>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Obstacle value is -300+done and training 10 times longer than v1 plus the steps are 300 ,,300.0,
94,outside_experiments,NWOO_v2,NWOO,0,9000,900000,0,"{'allow_reverse': False, 'grayscale': 1, 'show_info_panel': False, 'verbose': 0, 'discretize_actions': 'hard', 'num_tracks': 2, 'num_lanes': 2, 'num_lanes_changes': 0, 'num_obstacles': 100, 'max_time_out': 2.0, 'frames_per_state': 4, 'max_step_reward': 1, 'reward_fn': <function NWOO_n2n.__init__.<locals>.reward_fn at 0x7f7dd5937488>, 'random_obstacle_x_position': False, 'random_obstacle_shape': False, 'load_tracks_from': 'tracks', 'allow_outside': False}",4,Using new weights from Turn,,200.0,
